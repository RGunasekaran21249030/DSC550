{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qX1JruorqcPT"
   },
   "source": [
    "## 1. Neural Network Classifier with **Scikit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3z7TJaoZ2dts",
    "outputId": "95733e0e-7385-4337-cb84-f97712c42ac6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jsonlines in /usr/local/lib/python3.7/dist-packages (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "pip install jsonlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5iIwNB8YBcZ3",
    "outputId": "eb03c796-ab9a-4c3b-d6ad-5edae0c3443d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZHkbi6uLo7wj"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neural_network import MLPRegressor, MLPClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "from functools import wraps\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Load JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "H-GkwDTio6aB"
   },
   "outputs": [],
   "source": [
    "import jsonlines\n",
    "data = []\n",
    " \n",
    "with jsonlines.open('categorized-comments.jsonl') as reader:\n",
    "    for obj in reader.iter(type=dict, skip_invalid=True):\n",
    "        data.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gHyiGfDG6_j7"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "W1qNcnyTo7tY",
    "outputId": "0c7b98c5-814a-439f-c068-402d944f2aa2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>Barely better than Gabbert? He was significant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>Fuck the ducks and the Angels! But welcome to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>Should have drafted more WRs.\\n\\n- Matt Millen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>[Done](https://i.imgur.com/2YZ90pm.jpg)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>No!! NOO!!!!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912555</th>\n",
       "      <td>video_games</td>\n",
       "      <td>&amp;gt;any chance we can install the entire conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912556</th>\n",
       "      <td>video_games</td>\n",
       "      <td>No. It's probably only happened to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912557</th>\n",
       "      <td>video_games</td>\n",
       "      <td>I think most of the disappointment came from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912558</th>\n",
       "      <td>video_games</td>\n",
       "      <td>dishonored 1/2 looked like arse, so what the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912559</th>\n",
       "      <td>video_games</td>\n",
       "      <td>[removed]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912560 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                                txt\n",
       "0            sports  Barely better than Gabbert? He was significant...\n",
       "1            sports  Fuck the ducks and the Angels! But welcome to ...\n",
       "2            sports  Should have drafted more WRs.\\n\\n- Matt Millen...\n",
       "3            sports            [Done](https://i.imgur.com/2YZ90pm.jpg)\n",
       "4            sports                                      No!! NOO!!!!!\n",
       "...             ...                                                ...\n",
       "912555  video_games  &gt;any chance we can install the entire conte...\n",
       "912556  video_games             No. It's probably only happened to you\n",
       "912557  video_games  I think most of the disappointment came from t...\n",
       "912558  video_games  dishonored 1/2 looked like arse, so what the h...\n",
       "912559  video_games                                          [removed]\n",
       "\n",
       "[912560 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "FW3-NmEv0xCG"
   },
   "outputs": [],
   "source": [
    "df.dropna(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TH-t6xg5o7zy"
   },
   "outputs": [],
   "source": [
    " from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "hdLNVaIDo72k"
   },
   "outputs": [],
   "source": [
    "TfidfVectorizer = TfidfVectorizer(max_features=2000, stop_words=('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FQVVmgoWyjT9",
    "outputId": "c2337dde-8617-4882-9354-714ced65b8b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Remove Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "zd71bHcIt0fr"
   },
   "outputs": [],
   "source": [
    "def tokens(words):\n",
    "    words = re.sub(\"[^a-zA-Z]\",\" \", words)\n",
    "    text = words.lower().split()                   \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numbers(text):\n",
    "    new_text = []\n",
    "    for word in text.split():\n",
    "        if not re.search('\\d', word):\n",
    "            new_text.append(word)\n",
    "    return ' '.join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['txt'] = df['txt'].apply(tokens)\n",
    "df['txt'] = df['txt'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hTmRUJAL351S"
   },
   "outputs": [],
   "source": [
    "df['txt'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "id": "HRwrGGlk1oWq",
    "outputId": "78644293-ca77-4a95-dd67-fa73b16b2c42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat</th>\n",
       "      <th>txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sports</td>\n",
       "      <td>barely better than gabbert he was significantl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sports</td>\n",
       "      <td>fuck the ducks and the angels but welcome to a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sports</td>\n",
       "      <td>should have drafted more wrs matt millen probably</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sports</td>\n",
       "      <td>done https i imgur com yz pm jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sports</td>\n",
       "      <td>no noo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912555</th>\n",
       "      <td>video_games</td>\n",
       "      <td>gt any chance we can install the entire conten...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912556</th>\n",
       "      <td>video_games</td>\n",
       "      <td>no it s probably only happened to you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912557</th>\n",
       "      <td>video_games</td>\n",
       "      <td>i think most of the disappointment came from t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912558</th>\n",
       "      <td>video_games</td>\n",
       "      <td>dishonored looked like arse so what the hell w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912559</th>\n",
       "      <td>video_games</td>\n",
       "      <td>removed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>912557 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                cat                                                txt\n",
       "0            sports  barely better than gabbert he was significantl...\n",
       "1            sports  fuck the ducks and the angels but welcome to a...\n",
       "2            sports  should have drafted more wrs matt millen probably\n",
       "3            sports                   done https i imgur com yz pm jpg\n",
       "4            sports                                             no noo\n",
       "...             ...                                                ...\n",
       "912555  video_games  gt any chance we can install the entire conten...\n",
       "912556  video_games              no it s probably only happened to you\n",
       "912557  video_games  i think most of the disappointment came from t...\n",
       "912558  video_games  dishonored looked like arse so what the hell w...\n",
       "912559  video_games                                            removed\n",
       "\n",
       "[912557 rows x 2 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Split traning and Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "KVteVV2YU4_W"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df['txt']\n",
    "y = df['cat']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Nut3I2Mfw8Bu",
    "outputId": "cf35c4f8-e94f-42b5-fc4d-b31d61f06427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "video_games               542821\n",
      "sports                    122891\n",
      "science_and_technology     18704\n",
      "video_gamesdeo_games           1\n",
      "Name: cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fmxN71P7YD2C"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "JL4PvdKoYD5V"
   },
   "outputs": [],
   "source": [
    "classifer=MLPClassifier(hidden_layer_sizes=[15,10], max_iter=500, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nX48k7pz3Yv_",
    "outputId": "0a5979bd-434a-4681-9f65-38e5279268f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: preprocessing in /usr/local/lib/python3.7/dist-packages (0.1.13)\n",
      "Requirement already satisfied: nltk==3.2.4 in /usr/local/lib/python3.7/dist-packages (from preprocessing) (3.2.4)\n",
      "Requirement already satisfied: sphinx-rtd-theme==0.2.4 in /usr/local/lib/python3.7/dist-packages (from preprocessing) (0.2.4)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.2.4->preprocessing) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "pip install preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WFSh5CcRYD8Q",
    "outputId": "fdffb681-557d-4df6-8766-9da178067d68"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=False, max_df=1.0, max_features=10,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patte...\n",
       "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                               early_stopping=False, epsilon=1e-08,\n",
       "                               hidden_layer_sizes=(15, 10),\n",
       "                               learning_rate='constant',\n",
       "                               learning_rate_init=0.001, max_fun=15000,\n",
       "                               max_iter=200, momentum=0.9, n_iter_no_change=10,\n",
       "                               nesterovs_momentum=True, power_t=0.5,\n",
       "                               random_state=None, shuffle=True, solver='adam',\n",
       "                               tol=0.0001, validation_fraction=0.1,\n",
       "                               verbose=False, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import preprocessing\n",
    "\n",
    "tfidf = TfidfVectorizer(strip_accents=None, lowercase=False, \n",
    "                        max_features=10, \n",
    "                        ngram_range=(1,1))\n",
    "neural_net_pipeline = Pipeline([('vectorizer', tfidf), \n",
    "                                ('nn', MLPClassifier(hidden_layer_sizes=(15, 10)))])\n",
    "\n",
    "neural_net_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XxxAa--rUDHJ",
    "outputId": "9bb39916-424d-4a43-db7d-59d4bb43a6dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 79.29692294205313 %\n"
     ]
    }
   ],
   "source": [
    "y_pred = neural_net_pipeline.predict( X_val)\n",
    "\n",
    "print('Accuracy: {} %'.format(100 * accuracy_score(y_val, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euOH92538JlO"
   },
   "source": [
    "## 2. Neural Network Classifier with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "G4WTfQzN8OpR"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aMyAIHRL_VuH"
   },
   "outputs": [],
   "source": [
    "# Configuration options\n",
    "n_samples = 10000\n",
    "n_features = 6\n",
    "n_classes = 3\n",
    "n_labels = 2\n",
    "n_epochs = 50\n",
    "random_state = 42\n",
    "batch_size = 250\n",
    "verbosity = 1\n",
    "validation_split = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "jCxUHAwc8OsU"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "X = df['txt']\n",
    "y = df['cat']\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ls1P3dyM_gFH"
   },
   "outputs": [],
   "source": [
    "X, y = make_multilabel_classification(n_samples=n_samples, n_features=n_features, n_classes=n_classes, n_labels=n_labels, random_state=random_state)\n",
    "# Split into training and testing data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=random_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "01wxVcMH_ij9"
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation='relu', input_dim=n_features))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(n_classes, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OYo22aKi_kxW"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=binary_crossentropy,\n",
    "              optimizer=Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit data to model\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=n_epochs,\n",
    "          verbose=verbosity,\n",
    "          validation_split=validation_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7PjSTffZ8OwM",
    "outputId": "763c0c18-6ef8-4adc-c0c4-2a2f43a5d333"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "22/22 [==============================] - 1s 21ms/step - loss: 0.6740 - accuracy: 0.3623 - val_loss: 0.5441 - val_accuracy: 0.4030\n",
      "Epoch 2/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.5262 - accuracy: 0.4326 - val_loss: 0.4908 - val_accuracy: 0.4925\n",
      "Epoch 3/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4752 - accuracy: 0.5748 - val_loss: 0.4527 - val_accuracy: 0.6269\n",
      "Epoch 4/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.4363 - accuracy: 0.6532 - val_loss: 0.4260 - val_accuracy: 0.6284\n",
      "Epoch 5/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.4090 - accuracy: 0.6554 - val_loss: 0.4047 - val_accuracy: 0.6231\n",
      "Epoch 6/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.6416 - val_loss: 0.3843 - val_accuracy: 0.6276\n",
      "Epoch 7/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3634 - accuracy: 0.6302 - val_loss: 0.3687 - val_accuracy: 0.5978\n",
      "Epoch 8/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3495 - accuracy: 0.6157 - val_loss: 0.3589 - val_accuracy: 0.6201\n",
      "Epoch 9/50\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3396 - accuracy: 0.6233 - val_loss: 0.3529 - val_accuracy: 0.6299\n",
      "Epoch 10/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3330 - accuracy: 0.6138 - val_loss: 0.3469 - val_accuracy: 0.5970\n",
      "Epoch 11/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3291 - accuracy: 0.6183 - val_loss: 0.3465 - val_accuracy: 0.5694\n",
      "Epoch 12/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3261 - accuracy: 0.6190 - val_loss: 0.3431 - val_accuracy: 0.6373\n",
      "Epoch 13/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3225 - accuracy: 0.6235 - val_loss: 0.3392 - val_accuracy: 0.5881\n",
      "Epoch 14/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3199 - accuracy: 0.6063 - val_loss: 0.3373 - val_accuracy: 0.6142\n",
      "Epoch 15/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3175 - accuracy: 0.6175 - val_loss: 0.3376 - val_accuracy: 0.6254\n",
      "Epoch 16/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3165 - accuracy: 0.6129 - val_loss: 0.3338 - val_accuracy: 0.5903\n",
      "Epoch 17/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3155 - accuracy: 0.6095 - val_loss: 0.3319 - val_accuracy: 0.5724\n",
      "Epoch 18/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3140 - accuracy: 0.6246 - val_loss: 0.3318 - val_accuracy: 0.5649\n",
      "Epoch 19/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3130 - accuracy: 0.6039 - val_loss: 0.3333 - val_accuracy: 0.5940\n",
      "Epoch 20/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3109 - accuracy: 0.6114 - val_loss: 0.3324 - val_accuracy: 0.6493\n",
      "Epoch 21/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3107 - accuracy: 0.6170 - val_loss: 0.3299 - val_accuracy: 0.6030\n",
      "Epoch 22/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3096 - accuracy: 0.6006 - val_loss: 0.3280 - val_accuracy: 0.5425\n",
      "Epoch 23/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.6062 - val_loss: 0.3278 - val_accuracy: 0.5373\n",
      "Epoch 24/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3077 - accuracy: 0.5937 - val_loss: 0.3270 - val_accuracy: 0.6082\n",
      "Epoch 25/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3069 - accuracy: 0.6076 - val_loss: 0.3276 - val_accuracy: 0.5664\n",
      "Epoch 26/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3069 - accuracy: 0.6034 - val_loss: 0.3270 - val_accuracy: 0.5709\n",
      "Epoch 27/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3060 - accuracy: 0.6026 - val_loss: 0.3259 - val_accuracy: 0.5478\n",
      "Epoch 28/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3052 - accuracy: 0.5979 - val_loss: 0.3265 - val_accuracy: 0.5799\n",
      "Epoch 29/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3053 - accuracy: 0.6065 - val_loss: 0.3272 - val_accuracy: 0.5784\n",
      "Epoch 30/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3042 - accuracy: 0.5929 - val_loss: 0.3256 - val_accuracy: 0.6030\n",
      "Epoch 31/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.3037 - accuracy: 0.6211 - val_loss: 0.3261 - val_accuracy: 0.5478\n",
      "Epoch 32/50\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3040 - accuracy: 0.5853 - val_loss: 0.3266 - val_accuracy: 0.6075\n",
      "Epoch 33/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3032 - accuracy: 0.5972 - val_loss: 0.3290 - val_accuracy: 0.6522\n",
      "Epoch 34/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3032 - accuracy: 0.5991 - val_loss: 0.3250 - val_accuracy: 0.5851\n",
      "Epoch 35/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3024 - accuracy: 0.5847 - val_loss: 0.3226 - val_accuracy: 0.5918\n",
      "Epoch 36/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3024 - accuracy: 0.6082 - val_loss: 0.3225 - val_accuracy: 0.5739\n",
      "Epoch 37/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3019 - accuracy: 0.5875 - val_loss: 0.3247 - val_accuracy: 0.6224\n",
      "Epoch 38/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.3020 - accuracy: 0.6063 - val_loss: 0.3225 - val_accuracy: 0.5440\n",
      "Epoch 39/50\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3015 - accuracy: 0.5987 - val_loss: 0.3217 - val_accuracy: 0.5634\n",
      "Epoch 40/50\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 0.3018 - accuracy: 0.5888 - val_loss: 0.3223 - val_accuracy: 0.5567\n",
      "Epoch 41/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3014 - accuracy: 0.6091 - val_loss: 0.3226 - val_accuracy: 0.6127\n",
      "Epoch 42/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2998 - accuracy: 0.5897 - val_loss: 0.3204 - val_accuracy: 0.5813\n",
      "Epoch 43/50\n",
      "22/22 [==============================] - 0s 10ms/step - loss: 0.3001 - accuracy: 0.6106 - val_loss: 0.3216 - val_accuracy: 0.5821\n",
      "Epoch 44/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.2998 - accuracy: 0.5914 - val_loss: 0.3231 - val_accuracy: 0.5373\n",
      "Epoch 45/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2999 - accuracy: 0.5946 - val_loss: 0.3247 - val_accuracy: 0.5425\n",
      "Epoch 46/50\n",
      "22/22 [==============================] - 0s 7ms/step - loss: 0.3000 - accuracy: 0.6119 - val_loss: 0.3239 - val_accuracy: 0.5970\n",
      "Epoch 47/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2987 - accuracy: 0.5894 - val_loss: 0.3203 - val_accuracy: 0.5679\n",
      "Epoch 48/50\n",
      "22/22 [==============================] - 0s 9ms/step - loss: 0.2980 - accuracy: 0.6006 - val_loss: 0.3199 - val_accuracy: 0.5843\n",
      "Epoch 49/50\n",
      "22/22 [==============================] - 0s 12ms/step - loss: 0.2979 - accuracy: 0.6004 - val_loss: 0.3216 - val_accuracy: 0.5679\n",
      "Epoch 50/50\n",
      "22/22 [==============================] - 0s 8ms/step - loss: 0.2974 - accuracy: 0.5890 - val_loss: 0.3189 - val_accuracy: 0.5560\n",
      "Test loss: 0.2917522192001343 / Test accuracy: 0.5699999928474426\n"
     ]
    }
   ],
   "source": [
    "# Generate generalization metrics\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NvAz2S2yopw4"
   },
   "source": [
    "### 3. Classifying Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XjCAcwFsFHAA",
    "outputId": "e22d475c-d332-4559-d0db-b128076e6f8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: intel-tensorflow in /usr/local/lib/python3.7/dist-packages (2.5.0)\n",
      "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.12.0)\n",
      "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.7.4.3)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.12.1)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.2.0)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.12)\n",
      "Requirement already satisfied: grpcio~=1.34.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.34.1)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.12.4)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (0.36.2)\n",
      "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.19.5)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.6.3)\n",
      "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (1.15.0)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (3.1.0)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from intel-tensorflow) (2.5.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.9.2->intel-tensorflow) (56.1.0)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->intel-tensorflow) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (1.30.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (0.6.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->intel-tensorflow) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->intel-tensorflow) (4.0.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->intel-tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->intel-tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->intel-tensorflow) (0.2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->intel-tensorflow) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->intel-tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->intel-tensorflow) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->intel-tensorflow) (2.10)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->intel-tensorflow) (1.3.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.5->intel-tensorflow) (3.4.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.5->intel-tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->intel-tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "pip install intel-tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "X8lVBfcxflKy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "UpiFU78Ifs4o"
   },
   "outputs": [],
   "source": [
    "K.set_image_data_format(\"channels_first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "CqPVFPNyf10R"
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "iXf1k3R4f5T1"
   },
   "outputs": [],
   "source": [
    "channels = 1\n",
    "height = 28\n",
    "width = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "-8OHgX8Rf7Vr"
   },
   "outputs": [],
   "source": [
    "# data load from mnist dataset\n",
    "(data_train, target_train), (data_test, target_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "7FnHGv53f-EQ"
   },
   "outputs": [],
   "source": [
    "data_train = data_train.reshape(data_train.shape[0], channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "PGvVkK1Y9gtd"
   },
   "outputs": [],
   "source": [
    "data_test = data_test.reshape(data_test.shape[0],  channels, height, width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IWhy1y-oe6Ob",
    "outputId": "1e82aac1-6216-4b64-e507-cba1ffc88f56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 1, 28, 28)"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EjC7ZpNnoDJt",
    "outputId": "4df72d28-b5d8-4ba1-cf04-ef38ba2390e5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1, 28, 28)"
      ]
     },
     "execution_count": 62,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "hYacN9UcgCGh"
   },
   "outputs": [],
   "source": [
    "features_train = data_train / 255\n",
    "features_test = data_test / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "4wVVSlp8gDDF"
   },
   "outputs": [],
   "source": [
    "target_train = np_utils.to_categorical(target_train)\n",
    "target_test = np_utils.to_categorical(target_test)\n",
    "number_of_classes = target_test.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "A9grnQvegFWe"
   },
   "outputs": [],
   "source": [
    "# Model Creation \n",
    "\n",
    "network = Sequential()\n",
    "network.add(Conv2D(filters=64,\n",
    "                   kernel_size=(5, 5),\n",
    "                   input_shape=(channels, width, height),\n",
    "                   activation='relu',\n",
    "                   data_format='channels_first'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "SwrPH6okgHgp"
   },
   "outputs": [],
   "source": [
    "network.add(MaxPooling2D(pool_size=(2, 2),padding='same'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "6Wbs9uE4gJhq"
   },
   "outputs": [],
   "source": [
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "1RzuKP50gLOb"
   },
   "outputs": [],
   "source": [
    "network.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "yRyTt4mvgNaL"
   },
   "outputs": [],
   "source": [
    "network.add(Dense(128, activation=\"relu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "LH6rOF1CgPMe"
   },
   "outputs": [],
   "source": [
    "network.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "id": "vcpxgkcWgRp8"
   },
   "outputs": [],
   "source": [
    "network.add(Dense(number_of_classes, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "id": "JOBbYL1ygSW8"
   },
   "outputs": [],
   "source": [
    "network.compile(loss=\"categorical_crossentropy\", \n",
    "                optimizer=\"rmsprop\", \n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yJmvGhIgW4S",
    "outputId": "9f9231e1-852b-4e41-917b-63c8b84129cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f0b4a974090>"
      ]
     },
     "execution_count": 73,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fit(features_train,\n",
    "            target_train, # Target\n",
    "            epochs=2, \n",
    "            verbose=0, \n",
    "            batch_size=1000, \n",
    "            validation_data=(features_test, target_test)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKR-iGEjm8D-",
    "outputId": "706f7c7c-969e-46da-cb29-bd09b89ff5ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/50 [==============================] - 9s 174ms/step - loss: 12.8369 - accuracy: 0.9701\n"
     ]
    }
   ],
   "source": [
    "model_Accuracy=network.evaluate(data_test,target_test,batch_size=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRE96dzOnajT"
   },
   "source": [
    "## Conclusion :\n",
    "\n",
    "As part of this excercise, Studied the behaviour of convolutional neural network by using Keras. Train and Test dataset.\n",
    "\n",
    "The Accuracy of the  classify MSINT images using a convolutional neural network is 97%\n",
    "\n",
    "\n",
    "1. Using the multi-label classifier dataset, fitted a neural network classifier using scikit-learn. The Accuracy is 79%\n",
    "\n",
    "2. Using the multi-label classifier dataset, fitted a neural network classifier using Keras. The Accuracy is 57%\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
